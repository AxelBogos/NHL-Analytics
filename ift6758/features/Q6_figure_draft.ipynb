{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761def38",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\data\\\\tidy_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12844/1803726115.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mtiny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tidy_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mtiny\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtiny\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"x_coordinate\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#need to remove NaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ift6758\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ift6758\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ift6758\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ift6758\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ift6758\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ift6758\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ift6758\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ift6758\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\data\\\\tidy_data.csv'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Oct 10 10:07:11 2021\n",
    "\n",
    "@author: Marc-André, Van Binh\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import datetime\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "DATA_DIR = os.path.join('..', 'data')\n",
    "\n",
    "tiny = pd.read_csv(os.path.join(DATA_DIR, 'tidy_data.csv'))\n",
    "tiny =tiny.dropna(subset = [\"x_coordinate\"]) #need to remove NaN\n",
    "\n",
    "\n",
    "tiny['x_coordinate_adj'] = np.where(tiny[\"x_coordinate\"]<0, -tiny[\"x_coordinate\"], tiny[\"x_coordinate\"] )\n",
    "tiny['y_coordinate_adj'] = np.where(tiny[\"x_coordinate\"]<0, -tiny[\"y_coordinate\"]+42, tiny[\"y_coordinate\"]+42 )\n",
    "\n",
    "#year hard coded for now\n",
    "def compute_league_avg(df, year=2017):\n",
    "    \n",
    "    season = int(str(year) + str(year+1))\n",
    "    df_copy = df[df[\"season\"] == season].copy()\n",
    "    df_copy[\"coord_tuple\"] = df_copy[[\"x_coordinate_adj\",\"y_coordinate_adj\"]].apply(tuple, axis=1)\n",
    "    \n",
    "    \n",
    "    data_league= np.zeros((100,85))\n",
    "    \n",
    "    for i,j in df_copy['coord_tuple']:\n",
    "        if  np.isnan(i) or np.isnan(j):\n",
    "            pass\n",
    "        else:\n",
    "            data_league [int(i),int(j)] += 1\n",
    "    \n",
    "    \n",
    "    # total hours in the season\n",
    "    season_matchs_drop = df_copy.drop_duplicates(subset=['game_id'], keep='last') # use date to keep the same match with different date\n",
    "    season_hours = 0\n",
    "    for i, txt in enumerate (season_matchs_drop['game_time']):\n",
    "        time = txt.split(':')\n",
    "        hour_match = int(time[0]) / 60.0 + int(time[1]) / 3600.0\n",
    "        season_hours += max(hour_match, 1.0)\n",
    "    \n",
    "    \n",
    "    data_league = data_league/(season_hours * 2) #need to count each game twice since two team, need to replace with actual calculation of total game time\n",
    "    \n",
    "    #freq_dist = df_copy[[\"x_coordinate\",\"y_coordinate\"]].value_counts().reset_index(name=\"freq_league\")\n",
    "    #freq_dist[\"freq_league\"] = freq_dist[\"freq_league\"]/1271\n",
    "    return data_league\n",
    "\n",
    "#team and year hard coded for now\n",
    "def compute_team_avg(df, year=2017, team = \"Colorado Avalanche\"):\n",
    "    \n",
    "    season = int(str(year) + str(year+1))\n",
    "\n",
    "    df_copy = df[df[\"season\"] == season].copy()\n",
    "    df_copy2 = df_copy[df_copy['team']==team].copy()\n",
    "    df_copy2[\"coord_tuple\"] = df_copy2[[\"x_coordinate_adj\",\"y_coordinate_adj\"]].apply(tuple, axis=1)\n",
    "    \n",
    "    data_team = np.zeros((100,85))\n",
    "    \n",
    "    for i,j in df_copy2['coord_tuple']:\n",
    "        if  np.isnan(i) or np.isnan(j):\n",
    "            pass\n",
    "        else:\n",
    "            data_team[int(i),int(j)] += 1\n",
    "    \n",
    "    # count team hours\n",
    "    # count match as home & away in the season, drop duplicate for detail match\n",
    "    team_matchs = df_copy.loc[(df_copy[\"home_team\"] == team) | (df_copy['away_team'] == team)]  \n",
    "    team_matchs_drop = team_matchs.drop_duplicates(subset=['game_id'], keep='last') # use date to keep the same match with different date\n",
    "\n",
    "    team_hours = 0\n",
    "    for i, txt in enumerate (team_matchs_drop['game_time']):\n",
    "        time = txt.split(':')\n",
    "        hour_match = int(time[0]) / 60.0 + int(time[1]) / 3600.0\n",
    "        team_hours += max(hour_match, 1.0)\n",
    "    \n",
    "    data_team = data_team/team_hours \n",
    "    \n",
    "    return data_team\n",
    "\n",
    "def all_season_team_avg(df, start_year = 2016, end_year = 2020):\n",
    "    \n",
    "    team_year = {}\n",
    "    team_year_shoot = {}\n",
    "    # start year = 2016 and end year = 2020\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        \n",
    "        team_year[str(year)] = []\n",
    "        season = int(str(year) + str(year+1))\n",
    "\n",
    "        df_copy = df[df[\"season\"] == season].copy()\n",
    "        \n",
    "        # all teams have been presenting in the season by searching both in home_team and away_team\n",
    "        all_home_match = df_copy.drop_duplicates(subset=['home_team'], keep='last') # \n",
    "        all_away_match = df_copy.drop_duplicates(subset=['away_team'], keep='last') # \n",
    "        team_year[str(year)] = np.array(all_home_match['home_team'])\n",
    "        for _,team in enumerate (np.array(all_away_match['away_team'])):\n",
    "            if team not in team_year[str(year)]:\n",
    "                team_year[str(year)].append(team)\n",
    "   \n",
    "    for year in range(start_year, end_year + 1): \n",
    "        \n",
    "        # create a dict for all years and all teams\n",
    "        # each year includes many teams, each year, team include shoot_frequence array\n",
    "        team_year_shoot[str(year)] = {}\n",
    "        test_league = compute_league_avg(tiny, year)\n",
    "        for team in team_year[str(year)]:\n",
    "            \n",
    "            test_team = compute_team_avg(tiny, year, team)\n",
    "\n",
    "            test_total = test_team - test_league\n",
    "            test_total_fine = gaussian_filter(test_total, sigma=4) #smoothing results\n",
    "            \n",
    "            team_year_shoot[str(year)][team]  = test_total_fine\n",
    "        \n",
    "    return team_year_shoot\n",
    "        \n",
    "def plot_contourf(tiny, start_year = 2016, end_year = 2020):  \n",
    "    team_year_shoot = all_season_team_avg(tiny, start_year = start_year, end_year = end_year)    \n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for team in team_year_shoot[str(year)].keys():\n",
    "            print('the team name is = {} in the year = {}'.format(team, year))\n",
    "            test_total = team_year_shoot[str(year)][team]\n",
    "            \n",
    "            \n",
    "            xx, yy = np.mgrid[0:100:100j, -42:42:85j]\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            ax = fig.gca()\n",
    "            ax.set_xlim(0, 100)\n",
    "            ax.set_ylim(-42, 42)\n",
    "            #plots\n",
    "            cfset = ax.contourf(xx, yy, test_total, cmap='bwr')\n",
    "            cset = ax.contour(xx, yy, test_total, colors='k')\n",
    "            # Label plots\n",
    "            ax.clabel(cset, inline=1, fontsize=10)\n",
    "            ax.set_xlabel('X')\n",
    "            ax.set_ylabel('Y')\n",
    "            fig.colorbar(cfset)\n",
    "            cfset.set_clim(-0.03,0.03)#need to find a way to centralise white = 0\n",
    "            #cset.set_clim(-0.03,0.03)#need to find a way to centralise white = 0\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def contour(df):\n",
    "    \n",
    "    # initial data\n",
    "    # Xlabel, Ylabel create\n",
    "    xx, yy = np.mgrid[0:100:100j, -42:42:85j] \n",
    "    tiny_year_init = team_year_shoot[list(df.keys())[0]]\n",
    "    tiny_team_init = tiny_year_init[list(tiny_year_init.keys())[0]]\n",
    "\n",
    "    fig = go.Figure(data =\n",
    "        go.Contour(\n",
    "            x = xx[:,1],\n",
    "            y = yy[1,:], \n",
    "            z = np.rot90(np.fliplr(tiny_team_init)),\n",
    "            colorscale='RdBu',\n",
    "    \n",
    "        ))\n",
    "    \n",
    "    fig.add_layout_image(\n",
    "            dict(\n",
    "                source=\"../../figures/nhl_rink.png\",\n",
    "                xref=\"x\",\n",
    "                yref=\"y\",\n",
    "                x=-100,\n",
    "                y=45,\n",
    "                sizex=200,\n",
    "                sizey=90,\n",
    "                sizing=\"stretch\",\n",
    "                opacity=0.5,\n",
    "                layer=\"above\")\n",
    "    )\n",
    "    \n",
    "    updatemenu = []\n",
    "    buttons = []\n",
    "    buttons1 = []\n",
    "    \n",
    "    \n",
    "    # button with one option for each dataframe\n",
    "    for year in df.keys():\n",
    "        buttons.append(dict(method='restyle',\n",
    "                            label=year,\n",
    "                            visible=True\n",
    "                      ))\n",
    "    for year in df.keys():\n",
    "        for team in df[year].keys():\n",
    "            buttons1.append(dict(method='restyle',\n",
    "                                label=team,\n",
    "                                visible=True,\n",
    "                                args=['z',[np.rot90(np.fliplr(df[year][team]))]]\n",
    "                                )\n",
    "                          )\n",
    "    \n",
    "    # some adjustments to the updatemenus\n",
    "    updatemenu = []\n",
    "    your_menu = dict()\n",
    "    updatemenu.append(your_menu)\n",
    "    your_menu = dict()\n",
    "    updatemenu.append(your_menu)\n",
    "    \n",
    "    updatemenu[0]['buttons'] = buttons\n",
    "    updatemenu[0]['direction' ]     =\"down\"\n",
    "    updatemenu[0]['pad'       ]     ={\"r\": 10, \"t\": 10}\n",
    "    updatemenu[0]['showactive']     =True\n",
    "    updatemenu[0]['x'         ]     =0.06\n",
    "    updatemenu[0]['xanchor'   ]     =\"left\"\n",
    "    updatemenu[0]['y'         ]     =1.15\n",
    "    updatemenu[0]['yanchor'   ]     =\"top\"\n",
    "    \n",
    "    updatemenu[1]['buttons'] = buttons1\n",
    "    updatemenu[1]['direction' ]     =\"down\"\n",
    "    updatemenu[1]['pad'       ]     ={\"r\": 10, \"t\": 10}\n",
    "    updatemenu[1]['showactive']     =True\n",
    "    updatemenu[1]['x'         ]     =0.4\n",
    "    updatemenu[1]['xanchor'   ]     =\"left\"\n",
    "    updatemenu[1]['y'         ]     =1.15\n",
    "    updatemenu[1]['yanchor'   ]     =\"top\"\n",
    "    updatemenu1 = [ go.layout.Updatemenu(updatemenu[0]), go.layout.Updatemenu(updatemenu[1])]\n",
    "    # add dropdown menus to the figure\n",
    "    fig.update_layout(showlegend=False, updatemenus=updatemenu1)\n",
    "    \n",
    "    \n",
    "    fig.update_layout(\n",
    "        annotations=[\n",
    "            go.layout.Annotation(text=\"year\", x=0.01, xref=\"paper\", y=1.1, yref=\"paper\",\n",
    "                                 align=\"left\", showarrow=False),\n",
    "            go.layout.Annotation(text=\"team\", x=0.36, xref=\"paper\", y=1.1,\n",
    "                                 yref=\"paper\", showarrow=False),\n",
    "        ])\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "# run function\n",
    "#plot_contourf(tiny, start_year = 2016, end_year = 2016)\n",
    "team_year_shoot = all_season_team_avg(tiny, start_year = 2016, end_year = 2020)\n",
    "contour(team_year_shoot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612811f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift6758-conda-env",
   "language": "python",
   "name": "ift6758-conda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
